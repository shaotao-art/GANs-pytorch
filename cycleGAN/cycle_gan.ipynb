{"cells":[{"cell_type":"markdown","metadata":{},"source":["## CycleGAN\n","\n","* task: image translation: map from zebra/horse space to horse/zebra space\n","* model: $G$\n","* loss term: GAN loss + cycle loss + identity loss"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-19T08:08:46.902146Z","iopub.status.busy":"2022-02-19T08:08:46.900984Z","iopub.status.idle":"2022-02-19T08:08:47.569646Z","shell.execute_reply":"2022-02-19T08:08:47.568614Z","shell.execute_reply.started":"2022-02-19T08:08:46.902003Z"},"id":"IedLTuJ_caMf","pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torchvision\n","\n","import torch.optim as optim\n","from torch.utils.data import DataLoader,Dataset\n","\n","import torchvision.transforms as transforms\n","from PIL import Image\n","\n","from tqdm import tqdm\n","import os\n","import time\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"C_fHBFNxcaMl"},"source":["## define model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-19T08:08:52.335812Z","iopub.status.busy":"2022-02-19T08:08:52.335512Z","iopub.status.idle":"2022-02-19T08:08:52.360991Z","shell.execute_reply":"2022-02-19T08:08:52.357021Z","shell.execute_reply.started":"2022-02-19T08:08:52.335781Z"},"id":"7IlQ9HF3caMm","pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"source":["class Gen(nn.Module):\n","    def __init__(self) -> None:\n","        super(Gen, self).__init__()\n","    def forward(self, x):\n","\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-19T08:08:53.657507Z","iopub.status.busy":"2022-02-19T08:08:53.65664Z","iopub.status.idle":"2022-02-19T08:08:53.672163Z","shell.execute_reply":"2022-02-19T08:08:53.671112Z","shell.execute_reply.started":"2022-02-19T08:08:53.657466Z"},"id":"pAn2hl5tcaMn","pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"source":["class Disc(nn.Module):\n","    \"\"\"\n","    input: (N, 3, 256, 256)\n","    output: (N, 1, 30, 30)\n","    \"\"\"\n","\n","    def __init__(self, img_channel) -> None:\n","        super(Disc, self).__init__()\n","\n","\n","\n","    def forward(self, x):\n","        for layer in self.conv_layers:\n","            x = layer(x)\n","        x = self.sigmoid(x)\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"CrFthf0ocaMp"},"source":["## define some params"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-19T08:08:58.470061Z","iopub.status.busy":"2022-02-19T08:08:58.46794Z","iopub.status.idle":"2022-02-19T08:08:58.513659Z","shell.execute_reply":"2022-02-19T08:08:58.512297Z","shell.execute_reply.started":"2022-02-19T08:08:58.470013Z"},"id":"CzkfD5QpcaMp","pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"source":["LEARNING_RATE_GEN = 2e-4\n","LEARNING_RATE_DISC = 2e-4\n","LAMBDA_CYCLE = 10\n","LAMBDA_INDENTITY = 5\n","IMAGE_CHANNEL = 3\n","NUM_EPOCH = 10\n","BATCH_SIZE = 4\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""]},{"cell_type":"markdown","metadata":{},"source":["## prepare data"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"source":["# download and unzip dataset\n","! wget https://people.eecs.berkeley.edu/~taesung_park/CycleGAN/datasets/horse2zebra.zip && unzip horse2zebra.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"execution":{"iopub.execute_input":"2022-02-19T08:09:02.521745Z","iopub.status.busy":"2022-02-19T08:09:02.520846Z","iopub.status.idle":"2022-02-19T08:09:02.533084Z","shell.execute_reply":"2022-02-19T08:09:02.531959Z","shell.execute_reply.started":"2022-02-19T08:09:02.521689Z"},"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"source":["class horse_zebra(Dataset):\n","    def __init__(self, transform, path_horse=\"./horse2zebra/trainA/\",path_zebra=\"./horse2zebra/trainB/\"):\n","        self.path_horse = path_horse\n","        self.path_zebra = path_zebra\n","\n","        self.transform = transform\n","\n","        self.lst_horse = os.listdir(self.path_horse)\n","        self.lst_zebra = os.listdir(self.path_zebra)\n","\n","        # one thing about the dataset:\n","        # the num of horse pic != num of zebra pic\n","        self.length = max(len(self.lst_horse), len(self.lst_zebra))\n","\n","    def __len__(self):\n","        return self.length\n","\n","    def __getitem__(self, idx):\n","        # some pic on the dataset just have one channel\n","        # so need to use function: convert(\"RGB\")\n","        horse = Image.open(self.path_horse + self.lst_horse[torch.randint(len(self.lst_horse), size=(1,))]).convert(\"RGB\")\n","        zebra = Image.open(self.path_zebra + self.lst_zebra[idx]).convert(\"RGB\")\n","        if self.transform:\n","            horse = self.transform(horse)\n","            zebra = self.transform(zebra)\n","        return horse, zebra\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"execution":{"iopub.execute_input":"2022-02-19T08:09:03.418096Z","iopub.status.busy":"2022-02-19T08:09:03.417485Z","iopub.status.idle":"2022-02-19T08:09:03.425579Z","shell.execute_reply":"2022-02-19T08:09:03.424326Z","shell.execute_reply.started":"2022-02-19T08:09:03.41806Z"},"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"source":["transform = transforms.Compose([\n","    transforms.Resize((256,256)),\n","    transforms.ToTensor()\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"execution":{"iopub.execute_input":"2022-02-19T08:09:03.89652Z","iopub.status.busy":"2022-02-19T08:09:03.895461Z","iopub.status.idle":"2022-02-19T08:09:03.905109Z","shell.execute_reply":"2022-02-19T08:09:03.903964Z","shell.execute_reply.started":"2022-02-19T08:09:03.89647Z"},"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"source":["dataset = horse_zebra(transform)\n","dataloader = DataLoader(dataset, shuffle=True, batch_size=BATCH_SIZE)"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"execution":{"iopub.execute_input":"2022-02-19T08:09:04.851731Z","iopub.status.busy":"2022-02-19T08:09:04.851183Z","iopub.status.idle":"2022-02-19T08:09:04.898928Z","shell.execute_reply":"2022-02-19T08:09:04.897937Z","shell.execute_reply.started":"2022-02-19T08:09:04.851685Z"},"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"source":["# get test samples\n","# here, i choose to pick images in training set to visiualize whether the generator is learning\n","fix_horse, fix_zebra = next(iter(dataloader))"]},{"cell_type":"markdown","metadata":{},"source":["## keep the image buffer\n","\n","in the paper, they do not put the image newly generated by Gen into Disc, instead, they keep a buffer of generated image and then sample image from the buffer to Disc."]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"execution":{"iopub.execute_input":"2022-02-19T08:15:40.946534Z","iopub.status.busy":"2022-02-19T08:15:40.946227Z","iopub.status.idle":"2022-02-19T08:15:40.956287Z","shell.execute_reply":"2022-02-19T08:15:40.954836Z","shell.execute_reply.started":"2022-02-19T08:15:40.946503Z"},"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"source":["class ImageBuffer:\n","    def __init__(self, max_size=50):\n","        self.max_size = max_size\n","        self.data = []\n","\n","    def get_image(self, data):\n","        # data is what Gen generated and send in func\n","        # we will return a tensor of the same shape as data send in\n","        tensor_return = []\n","        for each in data:\n","            each = each.unsqueeze(0)\n","            if len(self.data) < self.max_size:\n","                self.data.append(each)\n","                tensor_return.append(each)\n","            else:\n","                # with prob == 0.5\n","                # we will update the buffer\n","                if torch.randn(1) < 0.5:\n","                    choose = torch.randint(self.max_size, size=(1,))\n","                    tensor_return.append(self.data[choose])\n","                    self.data[choose] = each\n","                else:\n","                    tensor_return.append(each)\n","        return torch.cat(tensor_return, dim=0)\n"]},{"cell_type":"markdown","metadata":{},"source":["## define optim and loss"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"execution":{"iopub.execute_input":"2022-02-19T08:09:09.065595Z","iopub.status.busy":"2022-02-19T08:09:09.064423Z","iopub.status.idle":"2022-02-19T08:09:09.073858Z","shell.execute_reply":"2022-02-19T08:09:09.072747Z","shell.execute_reply.started":"2022-02-19T08:09:09.065545Z"},"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"source":["def weight_init(m):\n","    \"\"\"\n","    init model's prams, if a layer is a conv layer: set the weight to N(0, 0.02), set the bias to constant 0.\n","    if a layer is a batch norm: set the weight to N(1, 0.02), set the bias to constant 0.\n","    usage: model.apply(weight_init)\n","\n","    params:\n","        m: model's layer\n","    return:\n","        None\n","    \"\"\"\n","    class_name = m.__class__.__name__\n","    if class_name.find(\"Conv\") != -1:\n","        torch.nn.init.normal_(m.weight.data, 0, 0.02)\n","        if hasattr(m, \"bias\") and m.bias is not None:\n","            torch.nn.init.constant_(m.bias.data, 0)\n","    if class_name.find(\"BatchNorm2d\") != -1:\n","        torch.nn.init.normal_(m.weight.data, 1, 0.02)\n","        torch.nn.init.constant_(m.bias.data, 0)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-19T08:09:10.295504Z","iopub.status.busy":"2022-02-19T08:09:10.294817Z","iopub.status.idle":"2022-02-19T08:09:12.86786Z","shell.execute_reply":"2022-02-19T08:09:12.866703Z","shell.execute_reply.started":"2022-02-19T08:09:10.295467Z"},"id":"OQtymYlfcaMs","pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"source":["G_H_Z = Gen(IMAGE_CHANNEL).to(DEVICE)\n","G_Z_H = Gen(IMAGE_CHANNEL).to(DEVICE)\n","\n","D_H = Disc(IMAGE_CHANNEL).to(DEVICE)\n","D_Z = Disc(IMAGE_CHANNEL).to(DEVICE)\n","\n","G_H_Z.apply(weight_init)\n","G_Z_H.apply(weight_init)\n","D_H.apply(weight_init)\n","D_Z.apply(weight_init)\n","\n","# optim two networks' params at the same time\n","opt_gen = optim.Adam(list(G_Z_H.parameters()) + list(G_H_Z.parameters()), lr=LEARNING_RATE_GEN, betas=(0.5, 0.999))\n","opt_d_h = optim.Adam(D_H.parameters(), lr=LEARNING_RATE_DISC, betas=(0.5, 0.999))\n","opt_d_z = optim.Adam(D_Z.parameters(), lr=LEARNING_RATE_DISC, betas=(0.5, 0.999))\n","\n","gan_criterion = nn.MSELoss()\n","cycle_criterion = nn.L1Loss()\n","identity_criterion = nn.L1Loss()\n","\n","model_checkpoint = {\n","    'G_H_Z':None,\n","    'G_Z_H':None,\n","    'D_Z':None,\n","    'D_H':None\n","}\n"]},{"cell_type":"markdown","metadata":{"id":"WY-a1xwqcaMt"},"source":["## set up the training loop"]},{"cell_type":"markdown","metadata":{"id":"zsfXD73McaMt","pycharm":{"name":"#%% md\n"}},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-19T08:34:23.243924Z","iopub.status.busy":"2022-02-19T08:34:23.243523Z","iopub.status.idle":"2022-02-19T08:34:24.042919Z","shell.execute_reply":"2022-02-19T08:34:24.041656Z","shell.execute_reply.started":"2022-02-19T08:34:23.24386Z"},"trusted":true},"outputs":[],"source":["! mkdir ./horse_output && mkdir ./zebra_output"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"execution":{"iopub.execute_input":"2022-02-19T08:43:23.732555Z","iopub.status.busy":"2022-02-19T08:43:23.731991Z","iopub.status.idle":"2022-02-19T08:43:23.744112Z","shell.execute_reply":"2022-02-19T08:43:23.742744Z","shell.execute_reply.started":"2022-02-19T08:43:23.732504Z"},"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"source":["# function to sample images\n","def sample_image(fix_horse, fix_zebra):\n","    fake_zebra = G_H_Z(fix_horse)\n","    fake_horse = G_Z_H(fix_zebra)\n","    cycle_horse = G_Z_H(fake_zebra)\n","    cycle_zebra = G_H_Z(fake_horse)\n","\n","    grid_real_horse = torchvision.utils.make_grid(fix_horse, nrow=1, normalize=True)\n","    grid_fake_zebra = torchvision.utils.make_grid(fake_zebra, nrow=1, normalize=True)\n","    grid_cycle_horse = torchvision.utils.make_grid(cycle_horse, nrow=1, normalize=True)\n","    grid_horse = torch.cat((grid_real_horse, grid_fake_zebra, grid_cycle_horse), dim=2)\n","\n","    grid_real_zebra = torchvision.utils.make_grid(fix_zebra, nrow=1, normalize=True)\n","    grid_fake_horse = torchvision.utils.make_grid(fake_horse, nrow=1, normalize=True)\n","    grid_cycle_zebra = torchvision.utils.make_grid(cycle_zebra, nrow=1, normalize=True)\n","    grid_zebra = torch.cat((grid_real_zebra, grid_fake_horse, grid_cycle_zebra), dim=2)\n","    torchvision.utils.save_image(grid_horse, f\"./horse_output/horse_epoch{epoch}_batch_{batch_idx}.png\", normalize=False)\n","    torchvision.utils.save_image(grid_zebra, f\"./zebra_output/zebra_epoch{epoch}_batch_{batch_idx}.png\", normalize=False)\n","    print(\"saving samples... done!\")\n","def save_checkpoint(dict, path=\"model.pth.tar\"):\n","    \"\"\"\n","    save the model and optim through a dictionary\n","     {\"model\": model.state_dict(), \"optim\": optim.state_dict()} (*)\n","\n","\n","    params:\n","        data: a dict of the structure (*) storing the model and optim\n","\n","    return:\n","        None\n","    \"\"\"\n","    now = time.strftime(\"%D_%H:%M\")\n","    print(f\"saving checkpoint at {now}, path is '{path}'\")\n","    torch.save(dict, path)\n","    print(\"saving model... done!\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fake_zebra_buffer = ImageBuffer()\n","fake_horse_buffer = ImageBuffer()"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"execution":{"iopub.execute_input":"2022-02-19T08:48:29.109919Z","iopub.status.busy":"2022-02-19T08:48:29.109597Z","iopub.status.idle":"2022-02-19T09:50:21.876477Z","shell.execute_reply":"2022-02-19T09:50:21.874668Z","shell.execute_reply.started":"2022-02-19T08:48:29.109863Z"},"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"source":["for epoch in range(NUM_EPOCH):\n","    loop = tqdm(dataloader, leave=True)\n","    for batch_idx, (horse, zebra) in enumerate(loop):\n","        G_H_Z.train()\n","        G_Z_H.train()\n","\n","        horse = horse.to(DEVICE)\n","        zebra = zebra.to(DEVICE)\n","\n","        #### train Gen ####\n","        opt_gen.zero_grad()\n","\n","        # train generator with the lastest generated image\n","        fake_horse = G_Z_H(zebra)\n","        d_h_fake = D_H(fake_horse)\n","        fake_zebra = G_H_Z(horse)\n","        d_z_fake = D_Z(fake_zebra)\n","        # gan loss\n","        gan_loss = gan_criterion(d_z_fake, torch.ones_like((d_z_fake)).to(DEVICE)) + gan_criterion(d_h_fake, torch.ones_like(d_h_fake))\n","\n","        # identity loss\n","        identity_zebra = G_H_Z(zebra)\n","        identity_horse = G_Z_H(horse)\n","        identity_loss = (identity_criterion(identity_zebra, zebra) + identity_criterion(identity_horse, horse)) * LAMBDA_INDENTITY\n","\n","        # cycle loss\n","        cycle_horse = G_Z_H(fake_zebra)\n","        cycle_zebra = G_H_Z(fake_horse)\n","        cycle_loss = (cycle_criterion(cycle_horse, horse) + cycle_criterion(cycle_zebra, zebra)) * LAMBDA_CYCLE\n","\n","        Gen_loss = gan_loss + identity_loss + cycle_loss\n","        Gen_loss.backward()\n","        opt_gen.step()\n","\n","        #### train discriminator ####\n","        opt_d_h.zero_grad()\n","        # train discriminator with the image from buffer\n","\n","        d_h_real = D_H(horse)\n","        # get image from buffer\n","        fake_horse_ = fake_horse_buffer.get_image(fake_horse)\n","        d_h_fake = D_H(fake_horse_.detach())\n","        d_h_loss = gan_criterion(d_h_real, torch.ones_like(d_h_real).to(DEVICE)) + \\\n","            gan_criterion(d_h_fake, torch.zeros_like(d_h_fake).to(DEVICE))\n","        d_h_loss.backward()\n","        opt_d_h.step()\n","\n","        opt_d_z.zero_grad()\n","        d_z_real = D_Z(zebra)\n","        fake_zebra_ = fake_zebra_buffer.get_image(fake_zebra)\n","        d_z_fake = D_Z(fake_zebra_.detach())\n","        d_z_loss = gan_criterion(d_z_real, torch.ones_like((d_z_real).to(DEVICE))) + \\\n","            gan_criterion(d_z_fake, torch.zeros_like(d_z_fake).to(DEVICE))\n","        d_z_loss.backward(retain_graph=True)\n","        opt_d_z.step()\n","\n","        if batch_idx % 40 == 0:\n","          G_Z_H.eval()\n","          G_H_Z.eval()\n","          with torch.no_grad():\n","                # sample gans output\n","                sample_image(fix_horse.to(DEVICE), fix_zebra.to(DEVICE))\n","\n","    # saving models\n","    model_checkpoint['G_H_Z']=G_H_Z.state_dict()\n","    model_checkpoint['G_Z_H']=G_Z_H.state_dict()\n","    model_checkpoint['D_Z']=D_Z.state_dict()\n","    model_checkpoint['D_H']=D_H.state_dict()\n","    save_checkpoint(model_checkpoint)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-19T08:44:53.191102Z","iopub.status.busy":"2022-02-19T08:44:53.190704Z","iopub.status.idle":"2022-02-19T08:44:53.989195Z","shell.execute_reply":"2022-02-19T08:44:53.988163Z","shell.execute_reply.started":"2022-02-19T08:44:53.191047Z"},"trusted":true},"outputs":[],"source":["!ls ./horse_output"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-19T09:53:15.993948Z","iopub.status.busy":"2022-02-19T09:53:15.993543Z","iopub.status.idle":"2022-02-19T09:53:20.71992Z","shell.execute_reply":"2022-02-19T09:53:20.718746Z","shell.execute_reply.started":"2022-02-19T09:53:15.9939Z"},"trusted":true},"outputs":[],"source":["! zip -r zebraoutput.zip zebra_output"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
