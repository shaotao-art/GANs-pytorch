{"cells":[{"cell_type":"markdown","metadata":{},"source":["## CycleGAN\n","\n","* task: image translation: map from zebra/horse space to horse/zebra space\n","* model: $G$ model: downsample - resnet block * N - upsample, $D$ model: patchGAN\n","* loss term: LSGAN loss + cycle loss + identity loss"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-02-19T08:08:46.902146Z","iopub.status.busy":"2022-02-19T08:08:46.900984Z","iopub.status.idle":"2022-02-19T08:08:47.569646Z","shell.execute_reply":"2022-02-19T08:08:47.568614Z","shell.execute_reply.started":"2022-02-19T08:08:46.902003Z"},"id":"IedLTuJ_caMf","pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torchvision\n","\n","import torch.optim as optim\n","from torch.utils.data import DataLoader,Dataset\n","\n","import torchvision.transforms as transforms\n","from PIL import Image\n","\n","from tqdm import tqdm\n","import os\n","import time\n","import numpy as np\n","import sys\n","sys.path.append(\"./../utils\")\n","from utils import BasicConv, init_weight, set_seed\n","import matplotlib.pyplot as plt\n","set_seed(2022)\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"C_fHBFNxcaMl"},"source":["## define model"]},{"cell_type":"markdown","metadata":{},"source":["### G's model\n","1. the model of G is the model used in style transfer\n","2. the model follow the struct of downsample -> ResBlock --> upsample"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["class ResidualBlock(nn.Module):\n","    def __init__(self, in_features, k_s, s, p):\n","        super(ResidualBlock, self).__init__()\n","\n","        conv_block =  [ nn.Conv2d(in_features, in_features, k_s, s, p, padding_mode=\"reflect\"),\n","                        nn.InstanceNorm2d(in_features),\n","                        nn.ReLU(inplace=True),\n","                        nn.Conv2d(in_features, in_features, k_s, s, p, padding_mode=\"reflect\"),\n","                        nn.InstanceNorm2d(in_features)  ]\n","\n","        self.conv_block = nn.Sequential(*conv_block)\n","\n","    def forward(self, x):\n","        return x + self.conv_block(x)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-02-19T08:08:52.335812Z","iopub.status.busy":"2022-02-19T08:08:52.335512Z","iopub.status.idle":"2022-02-19T08:08:52.360991Z","shell.execute_reply":"2022-02-19T08:08:52.357021Z","shell.execute_reply.started":"2022-02-19T08:08:52.335781Z"},"id":"7IlQ9HF3caMm","pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["StyleTransferModel(\n","  (head): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","    (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","    (2): ReLU(inplace=True)\n","    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=reflect)\n","    (4): InstanceNorm2d(129, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","    (5): ReLU(inplace=True)\n","    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=reflect)\n","    (7): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","    (8): ReLU(inplace=True)\n","  )\n","  (res_layers): Sequential(\n","    (0): ResidualBlock(\n","      (conv_block): Sequential(\n","        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n","        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n","        (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","      )\n","    )\n","    (1): ResidualBlock(\n","      (conv_block): Sequential(\n","        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n","        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n","        (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","      )\n","    )\n","    (2): ResidualBlock(\n","      (conv_block): Sequential(\n","        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n","        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n","        (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","      )\n","    )\n","    (3): ResidualBlock(\n","      (conv_block): Sequential(\n","        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n","        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n","        (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","      )\n","    )\n","    (4): ResidualBlock(\n","      (conv_block): Sequential(\n","        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n","        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n","        (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","      )\n","    )\n","    (5): ResidualBlock(\n","      (conv_block): Sequential(\n","        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n","        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n","        (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","      )\n","    )\n","    (6): ResidualBlock(\n","      (conv_block): Sequential(\n","        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n","        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n","        (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","      )\n","    )\n","    (7): ResidualBlock(\n","      (conv_block): Sequential(\n","        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n","        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n","        (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","      )\n","    )\n","  )\n","  (tail): Sequential(\n","    (0): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n","    (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","    (2): ReLU(inplace=True)\n","    (3): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n","    (4): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","    (5): ReLU(inplace=True)\n","    (6): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","  )\n",")\n","model params num:10198019\n","input sizetorch.Size([8, 3, 256, 256]), output size: torch.Size([8, 3, 256, 256])\n"]}],"source":["class Gen(nn.Module):\n","    \"\"\"\n","    follow structure: downsample -> ResNetBlock * N -> upsample\n","    input: (N, 3, 256, 256)\n","    output: (N, 3, 256, 256)\n","    \"\"\"\n","    def __init__(self, img_channel=3, num_resblock=8) -> None:\n","        super(Gen, self).__init__()\n","        self.head = nn.Sequential(\n","            nn.Conv2d(img_channel, 64, 7, 1, 3, padding_mode=\"reflect\"),\n","            nn.InstanceNorm2d(64),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(64, 128, 3, 2, 1, padding_mode=\"reflect\"),\n","            nn.InstanceNorm2d(129),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(128, 256, 3, 2, 1, padding_mode=\"reflect\"),\n","            nn.InstanceNorm2d(64),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","        reslayers = []\n","        for _ in range(num_resblock):\n","            reslayers.append(ResidualBlock(256, 3, 1, 1))\n","        self.res_layers = nn.Sequential(*reslayers)\n","\n","        self.tail = nn.Sequential(\n","            nn.ConvTranspose2d(256, 128, 3, 2, 1, 1),\n","            nn.InstanceNorm2d(128),\n","            nn.ReLU(inplace=True),\n","            nn.ConvTranspose2d(128, 64, 3, 2, 1, 1),\n","            nn.InstanceNorm2d(128),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(64, img_channel, 7, 1, 3, padding_mode=\"reflect\")\n","        )\n"," \n","    def forward(self, x):\n","        x = self.head(x)\n","        x = self.res_layers(x)\n","        x = self.tail(x)\n","        return x\n","        \n","def test_gen():\n","    model = Gen()\n","    x = torch.rand(8, 3, 256, 256)\n","    print(model)\n","    print(f\"model params num:{sum(p.numel() for p in model.parameters() if p.requires_grad==True)}\")\n","    print(f\"input size{x.shape}, output size: {model(x).shape}\")\n","test_gen()"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-02-19T08:08:53.657507Z","iopub.status.busy":"2022-02-19T08:08:53.65664Z","iopub.status.idle":"2022-02-19T08:08:53.672163Z","shell.execute_reply":"2022-02-19T08:08:53.671112Z","shell.execute_reply.started":"2022-02-19T08:08:53.657466Z"},"id":"pAn2hl5tcaMn","pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["model params num:1563457\n","input sizetorch.Size([8, 6, 256, 256]), output size: torch.Size([8, 1, 32, 32])\n"]}],"source":["class ConvBlock(nn.Module):\n","    def __init__(self, in_channel, out_channel, k_s, s, p, norm=True):\n","        super(ConvBlock, self).__init__()\n","\n","        conv_block =  [ nn.Conv2d(in_channel, out_channel, k_s, s, p),\n","                        nn.InstanceNorm2d(in_channel) if norm==True else nn.Identity(),\n","                        nn.LeakyReLU(0.2, inplace=True)]\n","\n","        self.conv_block = nn.Sequential(*conv_block)\n","\n","    def forward(self, x):\n","        return self.conv_block(x)\n","\n","\n","class Disc(nn.Module):\n","    \"\"\"\n","    input: (N, 3, 256, 256)\n","    output: (N, 1, 8, 8)\n","    \"\"\"\n","    def __init__(self, input_channel):\n","        super(Disc, self).__init__()\n","        main = []\n","        main.append(ConvBlock(input_channel, 64, 5, 2, 1, norm=False))\n","        main.append(ConvBlock(64, 128, 3, 2, 1))\n","        main.append(ConvBlock(128, 256, 3, 2, 1))\n","        main.append(ConvBlock(256, 512, 3, 1, 1))\n","        main.append(nn.Conv2d(512, 1, 3, 1, 1))\n","        self.model = nn.Sequential(*main)\n","\n","    def forward(self, x):\n","        return self.model(x)\n","def test_disc():\n","    model = Disc(6)\n","    x = torch.rand(8, 6, 256, 256)\n","    print(f\"model params num:{sum(p.numel() for p in model.parameters() if p.requires_grad==True)}\")\n","    print(f\"input size{x.shape}, output size: {model(x).shape}\")\n","test_disc()"]},{"cell_type":"markdown","metadata":{"id":"CrFthf0ocaMp"},"source":["## define some params"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-19T08:08:58.470061Z","iopub.status.busy":"2022-02-19T08:08:58.46794Z","iopub.status.idle":"2022-02-19T08:08:58.513659Z","shell.execute_reply":"2022-02-19T08:08:58.512297Z","shell.execute_reply.started":"2022-02-19T08:08:58.470013Z"},"id":"CzkfD5QpcaMp","pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"source":["LEARNING_RATE_GEN = 2e-4\n","LEARNING_RATE_DISC = 2e-4\n","LAMBDA_CYCLE = 10\n","LAMBDA_INDENTITY = 5\n","IMAGE_CHANNEL = 3\n","NUM_EPOCH = 10\n","BATCH_SIZE = 4\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""]},{"cell_type":"markdown","metadata":{},"source":["## prepare data"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"source":["# download and unzip dataset\n","! wget https://people.eecs.berkeley.edu/~taesung_park/CycleGAN/datasets/horse2zebra.zip && unzip horse2zebra.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"execution":{"iopub.execute_input":"2022-02-19T08:09:02.521745Z","iopub.status.busy":"2022-02-19T08:09:02.520846Z","iopub.status.idle":"2022-02-19T08:09:02.533084Z","shell.execute_reply":"2022-02-19T08:09:02.531959Z","shell.execute_reply.started":"2022-02-19T08:09:02.521689Z"},"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"source":["class HorseZebraData(Dataset):\n","    def __init__(self, transform, path_horse=\"./horse2zebra/trainA/\",path_zebra=\"./horse2zebra/trainB/\"):\n","        self.path_horse = path_horse\n","        self.path_zebra = path_zebra\n","\n","        self.transform = transform\n","\n","        self.lst_horse = os.listdir(self.path_horse)\n","        self.lst_zebra = os.listdir(self.path_zebra)\n","\n","        # one thing about the dataset:\n","        # the num of horse pic != num of zebra pic\n","        self.length = max(len(self.lst_horse), len(self.lst_zebra))\n","\n","    def __len__(self):\n","        return self.length\n","\n","    def __getitem__(self, idx):\n","        # some pic on the dataset just have one channel\n","        # so need to use function: convert(\"RGB\")\n","        horse = Image.open(self.path_horse + self.lst_horse[torch.randint(len(self.lst_horse), size=(1,))]).convert(\"RGB\")\n","        zebra = Image.open(self.path_zebra + self.lst_zebra[idx]).convert(\"RGB\")\n","        if self.transform:\n","            horse = self.transform(horse)\n","            zebra = self.transform(zebra)\n","        return horse, zebra\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"execution":{"iopub.execute_input":"2022-02-19T08:09:03.418096Z","iopub.status.busy":"2022-02-19T08:09:03.417485Z","iopub.status.idle":"2022-02-19T08:09:03.425579Z","shell.execute_reply":"2022-02-19T08:09:03.424326Z","shell.execute_reply.started":"2022-02-19T08:09:03.41806Z"},"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"source":["transform = transforms.Compose([\n","    transforms.Resize((256,256)),\n","    transforms.ToTensor()\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"execution":{"iopub.execute_input":"2022-02-19T08:09:03.89652Z","iopub.status.busy":"2022-02-19T08:09:03.895461Z","iopub.status.idle":"2022-02-19T08:09:03.905109Z","shell.execute_reply":"2022-02-19T08:09:03.903964Z","shell.execute_reply.started":"2022-02-19T08:09:03.89647Z"},"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"source":["dataset = HorseZebraData(transform)\n","dataloader = DataLoader(dataset, shuffle=True, batch_size=BATCH_SIZE)"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"execution":{"iopub.execute_input":"2022-02-19T08:09:04.851731Z","iopub.status.busy":"2022-02-19T08:09:04.851183Z","iopub.status.idle":"2022-02-19T08:09:04.898928Z","shell.execute_reply":"2022-02-19T08:09:04.897937Z","shell.execute_reply.started":"2022-02-19T08:09:04.851685Z"},"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"source":["# get test samples\n","# here, i choose to pick images in training set to visiualize whether the generator is learning\n","fix_horse, fix_zebra = next(iter(dataloader))\n","fix_horse_grid = torchvision.utils.make_grid(fix_horse, nrow=2)\n","fix_zebra_grid = torchvision.utils.make_grid(fix_zebra, nrow=2)\n","plt.subplot(1,2,1)\n","plt.imshow(fix_horse_grid.numpy())\n","plt.title(\"horse\")\n","plt.axis(\"off\")\n","plt.subplot(1,2,2)\n","plt.imshow(fix_zebra_grid.numpy())\n","plt.title(\"zebra\")\n","plt.axis(\"off\")\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## keep the image buffer\n","\n","in the paper, they do not put the image newly generated by Gen into Disc, instead, they keep a buffer of generated image and then sample image from the buffer to Disc."]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"execution":{"iopub.execute_input":"2022-02-19T08:15:40.946534Z","iopub.status.busy":"2022-02-19T08:15:40.946227Z","iopub.status.idle":"2022-02-19T08:15:40.956287Z","shell.execute_reply":"2022-02-19T08:15:40.954836Z","shell.execute_reply.started":"2022-02-19T08:15:40.946503Z"},"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"source":["class ImageBuffer:\n","    def __init__(self, max_size=50):\n","        self.max_size = max_size\n","        self.data = []\n","\n","    def get_image(self, data):\n","        # data is what Gen generated and send in func\n","        # we will return a tensor of the same shape as data send in\n","        tensor_return = []\n","        for each in data:\n","            each = each.unsqueeze(0)\n","            if len(self.data) < self.max_size:\n","                self.data.append(each)\n","                tensor_return.append(each)\n","            else:\n","                # with prob == 0.5\n","                # we will update the buffer\n","                if torch.randn(1) < 0.5:\n","                    choose = torch.randint(self.max_size, size=(1,))\n","                    tensor_return.append(self.data[choose])\n","                    self.data[choose] = each\n","                else:\n","                    tensor_return.append(each)\n","        return torch.cat(tensor_return, dim=0)\n"]},{"cell_type":"markdown","metadata":{},"source":["## define optim and loss"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-19T08:09:10.295504Z","iopub.status.busy":"2022-02-19T08:09:10.294817Z","iopub.status.idle":"2022-02-19T08:09:12.86786Z","shell.execute_reply":"2022-02-19T08:09:12.866703Z","shell.execute_reply.started":"2022-02-19T08:09:10.295467Z"},"id":"OQtymYlfcaMs","pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"source":["G_H_Z = Gen(IMAGE_CHANNEL).to(DEVICE)\n","G_Z_H = Gen(IMAGE_CHANNEL).to(DEVICE)\n","\n","D_H = Disc(IMAGE_CHANNEL).to(DEVICE)\n","D_Z = Disc(IMAGE_CHANNEL).to(DEVICE)\n","\n","G_H_Z.apply(init_weight)\n","G_Z_H.apply(init_weight)\n","\n","D_H.apply(init_weight)\n","D_Z.apply(init_weight)\n","\n","# optim two networks' params at the same time\n","opt_gen = optim.Adam(list(G_Z_H.parameters()) + list(G_H_Z.parameters()), lr=LEARNING_RATE_GEN, betas=(0.5, 0.999))\n","opt_d_h = optim.Adam(D_H.parameters(), lr=LEARNING_RATE_DISC, betas=(0.5, 0.999))\n","opt_d_z = optim.Adam(D_Z.parameters(), lr=LEARNING_RATE_DISC, betas=(0.5, 0.999))\n","\n","gan_criterion = nn.MSELoss()\n","cycle_criterion = nn.L1Loss()\n","identity_criterion = nn.L1Loss()\n","\n","model_checkpoint = {\n","    'G_H_Z':None,\n","    'G_Z_H':None,\n","    'D_Z':None,\n","    'D_H':None\n","}\n"]},{"cell_type":"markdown","metadata":{"id":"WY-a1xwqcaMt"},"source":["## set up the training loop"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"execution":{"iopub.execute_input":"2022-02-19T08:43:23.732555Z","iopub.status.busy":"2022-02-19T08:43:23.731991Z","iopub.status.idle":"2022-02-19T08:43:23.744112Z","shell.execute_reply":"2022-02-19T08:43:23.742744Z","shell.execute_reply.started":"2022-02-19T08:43:23.732504Z"},"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"source":["# function to sample images\n","def sample_image(fix_horse, fix_zebra):\n","    fake_zebra = G_H_Z(fix_horse)\n","    fake_horse = G_Z_H(fix_zebra)\n","    cycle_horse = G_Z_H(fake_zebra)\n","    cycle_zebra = G_H_Z(fake_horse)\n","\n","    grid_real_horse = torchvision.utils.make_grid(fix_horse, nrow=1, normalize=True)\n","    grid_fake_zebra = torchvision.utils.make_grid(fake_zebra, nrow=1, normalize=True)\n","    grid_cycle_horse = torchvision.utils.make_grid(cycle_horse, nrow=1, normalize=True)\n","    grid_horse = torch.cat((grid_real_horse, grid_fake_zebra, grid_cycle_horse), dim=2)\n","\n","    grid_real_zebra = torchvision.utils.make_grid(fix_zebra, nrow=1, normalize=True)\n","    grid_fake_horse = torchvision.utils.make_grid(fake_horse, nrow=1, normalize=True)\n","    grid_cycle_zebra = torchvision.utils.make_grid(cycle_zebra, nrow=1, normalize=True)\n","    grid_zebra = torch.cat((grid_real_zebra, grid_fake_horse, grid_cycle_zebra), dim=2)\n","    torchvision.utils.save_image(grid_horse, f\"./horse_output/horse_epoch{epoch}_batch_{batch_idx}.png\", normalize=False)\n","    torchvision.utils.save_image(grid_zebra, f\"./zebra_output/zebra_epoch{epoch}_batch_{batch_idx}.png\", normalize=False)\n","    print(\"saving samples... done!\")\n","\n","\n","def save_checkpoint(dict, path=\"model.pth.tar\"):\n","    \"\"\"\n","    save the model and optim through a dictionary\n","     {\"model\": model.state_dict(), \"optim\": optim.state_dict()} (*)\n","\n","\n","    params:\n","        data: a dict of the structure (*) storing the model and optim\n","\n","    return:\n","        None\n","    \"\"\"\n","    now = time.strftime(\"%D_%H:%M\")\n","    print(f\"saving checkpoint at {now}, path is '{path}'\")\n","    torch.save(dict, path)\n","    print(\"saving model... done!\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fake_zebra_buffer = ImageBuffer()\n","fake_horse_buffer = ImageBuffer()"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"execution":{"iopub.execute_input":"2022-02-19T08:48:29.109919Z","iopub.status.busy":"2022-02-19T08:48:29.109597Z","iopub.status.idle":"2022-02-19T09:50:21.876477Z","shell.execute_reply":"2022-02-19T09:50:21.874668Z","shell.execute_reply.started":"2022-02-19T08:48:29.109863Z"},"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"source":["for epoch in range(NUM_EPOCH):\n","    loop = tqdm(dataloader, leave=True)\n","    for batch_idx, (horse, zebra) in enumerate(loop):\n","        G_H_Z.train()\n","        G_Z_H.train()\n","\n","        horse = horse.to(DEVICE)\n","        zebra = zebra.to(DEVICE)\n","\n","        #### train Gen ####\n","        opt_gen.zero_grad()\n","\n","        # train generator with the lastest generated image\n","        fake_horse = G_Z_H(zebra)\n","        d_h_fake = D_H(fake_horse)\n","        fake_zebra = G_H_Z(horse)\n","        d_z_fake = D_Z(fake_zebra)\n","        # gan loss\n","        gan_loss = gan_criterion(d_z_fake, torch.ones_like((d_z_fake)).to(DEVICE)) + gan_criterion(d_h_fake, torch.ones_like(d_h_fake))\n","\n","        # identity loss\n","        identity_zebra = G_H_Z(zebra)\n","        identity_horse = G_Z_H(horse)\n","        identity_loss = (identity_criterion(identity_zebra, zebra) + identity_criterion(identity_horse, horse)) * LAMBDA_INDENTITY\n","\n","        # cycle loss\n","        cycle_horse = G_Z_H(fake_zebra)\n","        cycle_zebra = G_H_Z(fake_horse)\n","        cycle_loss = (cycle_criterion(cycle_horse, horse) + cycle_criterion(cycle_zebra, zebra)) * LAMBDA_CYCLE\n","\n","        Gen_loss = gan_loss + identity_loss + cycle_loss\n","        Gen_loss.backward()\n","        opt_gen.step()\n","\n","        #### train discriminator ####\n","        opt_d_h.zero_grad()\n","        # train discriminator with the image from buffer\n","\n","        d_h_real = D_H(horse)\n","        # get image from buffer\n","        fake_horse_ = fake_horse_buffer.get_image(fake_horse)\n","        d_h_fake = D_H(fake_horse_.detach())\n","        d_h_loss = gan_criterion(d_h_real, torch.ones_like(d_h_real).to(DEVICE)) + \\\n","            gan_criterion(d_h_fake, torch.zeros_like(d_h_fake).to(DEVICE))\n","        d_h_loss.backward()\n","        opt_d_h.step()\n","\n","        opt_d_z.zero_grad()\n","        d_z_real = D_Z(zebra)\n","        fake_zebra_ = fake_zebra_buffer.get_image(fake_zebra)\n","        d_z_fake = D_Z(fake_zebra_.detach())\n","        d_z_loss = gan_criterion(d_z_real, torch.ones_like((d_z_real).to(DEVICE))) + \\\n","            gan_criterion(d_z_fake, torch.zeros_like(d_z_fake).to(DEVICE))\n","        d_z_loss.backward(retain_graph=True)\n","        opt_d_z.step()\n","\n","        if batch_idx % 40 == 0:\n","          G_Z_H.eval()\n","          G_H_Z.eval()\n","          with torch.no_grad():\n","                # sample gans output\n","                sample_image(fix_horse.to(DEVICE), fix_zebra.to(DEVICE))\n","\n","    # saving models\n","    model_checkpoint['G_H_Z']=G_H_Z.state_dict()\n","    model_checkpoint['G_Z_H']=G_Z_H.state_dict()\n","    model_checkpoint['D_Z']=D_Z.state_dict()\n","    model_checkpoint['D_H']=D_H.state_dict()\n","    save_checkpoint(model_checkpoint)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-19T08:44:53.191102Z","iopub.status.busy":"2022-02-19T08:44:53.190704Z","iopub.status.idle":"2022-02-19T08:44:53.989195Z","shell.execute_reply":"2022-02-19T08:44:53.988163Z","shell.execute_reply.started":"2022-02-19T08:44:53.191047Z"},"trusted":true},"outputs":[],"source":["!ls ./horse_output"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-19T09:53:15.993948Z","iopub.status.busy":"2022-02-19T09:53:15.993543Z","iopub.status.idle":"2022-02-19T09:53:20.71992Z","shell.execute_reply":"2022-02-19T09:53:20.718746Z","shell.execute_reply.started":"2022-02-19T09:53:15.9939Z"},"trusted":true},"outputs":[],"source":["! zip -r zebraoutput.zip zebra_output"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":4}
