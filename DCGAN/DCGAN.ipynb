{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# DCGAN\n",
    "* task: image generation\n",
    "* model:\n",
    "    1. $G$ take random noise and output a image\n",
    "    2. $D$ take a image and output a patch\n",
    "* loss: naive GAN loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## do some imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "VFgOaTxfAWQW"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append(\"./../utils\")\n",
    "from utils import BasicConv, init_weight, set_seed\n",
    "\n",
    "set_seed(2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $G$'s model\n",
    "1. gradually decreasing channel and increasing resolution\n",
    "2. in the first conv block, map from noise (N, 100, 1, 1) to init image (N, 1024, 4, 4) then follow $1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model params num:599427\n",
      "input sizetorch.Size([8, 100, 1, 1]), output size: torch.Size([8, 3, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "class Gen(nn.Module):\n",
    "    \"\"\"\n",
    "    input: (N, 100, 1, 1)\n",
    "    output: (N, 3, 64, 64)\n",
    "    \"\"\"\n",
    "    def __init__(self, noise_channel, img_channel) -> None:\n",
    "        super(Gen, self).__init__()\n",
    "        self.init_conv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(noise_channel, 256, 4, 1, 0),\n",
    "            nn.LeakyReLU(0.2, True))\n",
    "        main = []\n",
    "        main.append(UpConv(256, 128))\n",
    "        main.append(UpConv(128, 64))\n",
    "        main.append(UpConv(64, 64))\n",
    "        main.append(UpConv(64, 32))\n",
    "        main.append(nn.Conv2d(32, img_channel, 3, 1, 1))\n",
    "        self.model = nn.Sequential(*main)\n",
    "    \n",
    "    def forward(self, x): \n",
    "        x = self.init_conv(x)       \n",
    "        return torch.clip(self.model(x), 0, 1)\n",
    "\n",
    "class UpConv(nn.Module):\n",
    "    \"\"\"\n",
    "    input: (N, in_channel, H, W)\n",
    "    output: (N, out_channel, 2*H, 2*W)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channel, out_channel) -> None:\n",
    "        super(UpConv, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channel, out_channel, 2, 2, 0),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "def test_gen():\n",
    "    model = Gen(100, 3)\n",
    "    x = torch.rand(8, 100, 1, 1)\n",
    "    print(f\"model params num:{sum(p.numel() for p in model.parameters() if p.requires_grad==True)}\")\n",
    "    print(f\"input size{x.shape}, output size: {model(x).shape}\")\n",
    "test_gen()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $D$'s model\n",
    "1. gradually increasing channel and decreasing resolution\n",
    "2. in the last conv block, map from 256 channel image to 1 channel image\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "kcC7Se0c_8MM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model params num:407041\n",
      "input sizetorch.Size([8, 3, 64, 64]), output size: torch.Size([8, 1, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "class Disc(nn.Module):\n",
    "    \"\"\"\n",
    "    input: (N, 3, 64, 64)\n",
    "    output: (N, 1, 8, 8)\n",
    "    \"\"\"\n",
    "    def __init__(self, img_channel):\n",
    "        super(Disc, self).__init__()\n",
    "        main = []\n",
    "        main .append(BasicConv(img_channel, 256, 5, 2, leaky_relu=False))\n",
    "        main.append(BasicConv(256, 128, 3, 2, leaky_relu=False))\n",
    "        main.append(BasicConv(128, 64, 3, 2, leaky_relu=False))\n",
    "        main.append(BasicConv(64, 32, 3, 1, leaky_relu=False))\n",
    "        main.append(nn.Conv2d(32, 1, 3, 1, 1))\n",
    "        self.model = nn.Sequential(*main)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        return self.sigmoid(self.model(x))\n",
    "def test_disc():\n",
    "    model = Disc(3)\n",
    "    x = torch.rand(8, 3, 64, 64)\n",
    "    print(f\"model params num:{sum(p.numel() for p in model.parameters() if p.requires_grad==True)}\")\n",
    "    print(f\"input size{x.shape}, output size: {model(x).shape}\")\n",
    "test_disc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## define params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "l_r_gen = 2e-4\n",
    "l_r_disc = 2e-4\n",
    "\n",
    "NUM_EPOCH = 5\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "noise_channel = 100\n",
    "img_channel = 3\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "fix_noise = torch.randn(32, 100, 1, 1).to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "  transforms.Resize(64),\n",
    "  transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## define optim, loss ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gen(\n",
      "  (net): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (4): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (5): Tanh()\n",
      "  )\n",
      ") Discriminator(\n",
      "  (disc): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): LeakyReLU(negative_slope=0.2)\n",
      "    (2): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.2)\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.2)\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.2)\n",
      "    )\n",
      "    (5): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1))\n",
      "  )\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "gen = Gen(noise_channel, img_channel).to(DEVICE)\n",
    "disc = Disc(img_channel).to(DEVICE)\n",
    "\n",
    "gen.apply(init_weight)\n",
    "disc.apply(init_weight)\n",
    "\n",
    "opt_gen = optim.Adam(gen.parameters(), lr=l_r_gen, betas=(0.5, 0.999))\n",
    "opt_disc = optim.Adam(disc.parameters(), lr=l_r_disc, betas=(0.5, 0.999))\n",
    "\n",
    "loss = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## set up the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x94dooCjCs_S"
   },
   "outputs": [],
   "source": [
    "real_writer = SummaryWriter(log_dir=\"./run/DCGAN/real\")\n",
    "fake_writer = SummaryWriter(log_dir=\"./run/DCGAN/fake\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 180771,
     "status": "error",
     "timestamp": 1643504916329,
     "user": {
      "displayName": "tao shao",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh7VKvujGnKvxsIt7poP71nLcXe9HHvoq9IsZSw=s64",
      "userId": "08804023574068554959"
     },
     "user_tz": -480
    },
    "id": "cXUzISQdAdWV",
    "outputId": "b9b374da-4e02-4d0b-8a8b-1415aa49f7fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[ 0/ 5], batch[   0/ 938], loss:[G:2.994233,D:0.742415]\n",
      "epoch:[ 0/ 5], batch[  10/ 938], loss:[G:6.528258,D:0.177330]\n",
      "epoch:[ 0/ 5], batch[  20/ 938], loss:[G:7.242606,D:0.367552]\n",
      "epoch:[ 0/ 5], batch[  30/ 938], loss:[G:8.267038,D:0.344901]\n",
      "epoch:[ 0/ 5], batch[  40/ 938], loss:[G:7.915555,D:0.305940]\n",
      "epoch:[ 0/ 5], batch[  50/ 938], loss:[G:6.081284,D:0.122923]\n",
      "epoch:[ 0/ 5], batch[  60/ 938], loss:[G:6.069611,D:0.097718]\n",
      "epoch:[ 0/ 5], batch[  70/ 938], loss:[G:4.182104,D:1.246040]\n",
      "epoch:[ 0/ 5], batch[  80/ 938], loss:[G:4.549936,D:0.176098]\n",
      "epoch:[ 0/ 5], batch[  90/ 938], loss:[G:2.798174,D:0.026363]\n",
      "epoch:[ 0/ 5], batch[ 100/ 938], loss:[G:7.296311,D:0.254291]\n",
      "epoch:[ 0/ 5], batch[ 110/ 938], loss:[G:3.177748,D:0.059517]\n",
      "epoch:[ 0/ 5], batch[ 120/ 938], loss:[G:2.310700,D:0.075628]\n",
      "epoch:[ 0/ 5], batch[ 130/ 938], loss:[G:2.896574,D:0.046743]\n",
      "epoch:[ 0/ 5], batch[ 140/ 938], loss:[G:2.360650,D:0.076969]\n",
      "epoch:[ 0/ 5], batch[ 150/ 938], loss:[G:1.848305,D:0.078786]\n",
      "epoch:[ 0/ 5], batch[ 160/ 938], loss:[G:2.284948,D:0.045423]\n",
      "epoch:[ 0/ 5], batch[ 170/ 938], loss:[G:2.226999,D:0.047743]\n",
      "epoch:[ 0/ 5], batch[ 180/ 938], loss:[G:2.065823,D:0.458479]\n",
      "epoch:[ 0/ 5], batch[ 190/ 938], loss:[G:2.055694,D:0.151661]\n",
      "epoch:[ 0/ 5], batch[ 200/ 938], loss:[G:1.785791,D:0.086702]\n",
      "epoch:[ 0/ 5], batch[ 210/ 938], loss:[G:2.128876,D:0.094391]\n",
      "epoch:[ 0/ 5], batch[ 220/ 938], loss:[G:2.271540,D:0.068457]\n",
      "epoch:[ 0/ 5], batch[ 230/ 938], loss:[G:0.850689,D:0.331338]\n",
      "epoch:[ 0/ 5], batch[ 240/ 938], loss:[G:1.590677,D:0.133738]\n",
      "epoch:[ 0/ 5], batch[ 250/ 938], loss:[G:1.561143,D:0.266538]\n",
      "epoch:[ 0/ 5], batch[ 260/ 938], loss:[G:2.270145,D:0.067615]\n",
      "epoch:[ 0/ 5], batch[ 270/ 938], loss:[G:4.872033,D:0.586251]\n",
      "epoch:[ 0/ 5], batch[ 280/ 938], loss:[G:1.774896,D:0.108320]\n",
      "epoch:[ 0/ 5], batch[ 290/ 938], loss:[G:1.414039,D:0.117827]\n",
      "epoch:[ 0/ 5], batch[ 300/ 938], loss:[G:1.720595,D:0.082978]\n",
      "epoch:[ 0/ 5], batch[ 310/ 938], loss:[G:2.466084,D:0.061703]\n",
      "epoch:[ 0/ 5], batch[ 320/ 938], loss:[G:1.992365,D:0.061376]\n",
      "epoch:[ 0/ 5], batch[ 330/ 938], loss:[G:1.469764,D:0.081352]\n",
      "epoch:[ 0/ 5], batch[ 340/ 938], loss:[G:2.275586,D:0.038344]\n",
      "epoch:[ 0/ 5], batch[ 350/ 938], loss:[G:1.875893,D:0.072110]\n",
      "epoch:[ 0/ 5], batch[ 360/ 938], loss:[G:2.557102,D:0.055611]\n",
      "epoch:[ 0/ 5], batch[ 370/ 938], loss:[G:2.809523,D:6.736979]\n",
      "epoch:[ 0/ 5], batch[ 380/ 938], loss:[G:1.293445,D:0.296367]\n",
      "epoch:[ 0/ 5], batch[ 390/ 938], loss:[G:1.680674,D:0.167260]\n",
      "epoch:[ 0/ 5], batch[ 400/ 938], loss:[G:1.766669,D:0.109033]\n",
      "epoch:[ 0/ 5], batch[ 410/ 938], loss:[G:1.782789,D:0.068404]\n",
      "epoch:[ 0/ 5], batch[ 420/ 938], loss:[G:2.241079,D:0.062227]\n",
      "epoch:[ 0/ 5], batch[ 430/ 938], loss:[G:1.711706,D:0.140699]\n",
      "epoch:[ 0/ 5], batch[ 440/ 938], loss:[G:2.003002,D:0.097683]\n",
      "epoch:[ 0/ 5], batch[ 450/ 938], loss:[G:1.884261,D:0.053368]\n",
      "epoch:[ 0/ 5], batch[ 460/ 938], loss:[G:1.885236,D:0.064523]\n",
      "epoch:[ 0/ 5], batch[ 470/ 938], loss:[G:1.032411,D:1.781193]\n",
      "epoch:[ 0/ 5], batch[ 480/ 938], loss:[G:1.819089,D:0.097795]\n",
      "epoch:[ 0/ 5], batch[ 490/ 938], loss:[G:1.717940,D:0.059490]\n",
      "epoch:[ 0/ 5], batch[ 500/ 938], loss:[G:0.863794,D:0.340566]\n",
      "epoch:[ 0/ 5], batch[ 510/ 938], loss:[G:1.730322,D:0.231774]\n",
      "epoch:[ 0/ 5], batch[ 520/ 938], loss:[G:2.110671,D:0.128840]\n",
      "epoch:[ 0/ 5], batch[ 530/ 938], loss:[G:1.731365,D:0.099569]\n",
      "epoch:[ 0/ 5], batch[ 540/ 938], loss:[G:2.451264,D:0.209584]\n",
      "epoch:[ 0/ 5], batch[ 550/ 938], loss:[G:2.478491,D:0.519503]\n",
      "epoch:[ 0/ 5], batch[ 560/ 938], loss:[G:1.771039,D:0.114769]\n",
      "epoch:[ 0/ 5], batch[ 570/ 938], loss:[G:1.715565,D:0.082637]\n",
      "epoch:[ 0/ 5], batch[ 580/ 938], loss:[G:3.161855,D:0.236223]\n",
      "epoch:[ 0/ 5], batch[ 590/ 938], loss:[G:0.847828,D:0.418969]\n",
      "epoch:[ 0/ 5], batch[ 600/ 938], loss:[G:1.191229,D:0.384209]\n",
      "epoch:[ 0/ 5], batch[ 610/ 938], loss:[G:2.611752,D:0.438359]\n",
      "epoch:[ 0/ 5], batch[ 620/ 938], loss:[G:0.981583,D:0.251898]\n",
      "epoch:[ 0/ 5], batch[ 630/ 938], loss:[G:1.604717,D:0.180135]\n",
      "epoch:[ 0/ 5], batch[ 640/ 938], loss:[G:1.688919,D:0.218849]\n",
      "epoch:[ 0/ 5], batch[ 650/ 938], loss:[G:1.406868,D:0.177916]\n",
      "epoch:[ 0/ 5], batch[ 660/ 938], loss:[G:1.555009,D:0.160905]\n",
      "epoch:[ 0/ 5], batch[ 670/ 938], loss:[G:1.611069,D:0.196714]\n",
      "epoch:[ 0/ 5], batch[ 680/ 938], loss:[G:1.779474,D:0.164793]\n",
      "epoch:[ 0/ 5], batch[ 690/ 938], loss:[G:1.986040,D:0.269221]\n",
      "epoch:[ 0/ 5], batch[ 700/ 938], loss:[G:1.425727,D:0.144087]\n",
      "epoch:[ 0/ 5], batch[ 710/ 938], loss:[G:0.996820,D:0.196548]\n",
      "epoch:[ 0/ 5], batch[ 720/ 938], loss:[G:1.281489,D:0.138096]\n",
      "epoch:[ 0/ 5], batch[ 730/ 938], loss:[G:1.154488,D:0.210941]\n",
      "epoch:[ 0/ 5], batch[ 740/ 938], loss:[G:1.825302,D:0.136456]\n",
      "epoch:[ 0/ 5], batch[ 750/ 938], loss:[G:1.414944,D:0.085765]\n",
      "epoch:[ 0/ 5], batch[ 760/ 938], loss:[G:1.688532,D:0.135525]\n",
      "epoch:[ 0/ 5], batch[ 770/ 938], loss:[G:1.154586,D:0.120660]\n",
      "epoch:[ 0/ 5], batch[ 780/ 938], loss:[G:3.114930,D:0.250614]\n",
      "epoch:[ 0/ 5], batch[ 790/ 938], loss:[G:2.083235,D:0.149019]\n",
      "epoch:[ 0/ 5], batch[ 800/ 938], loss:[G:1.928277,D:0.246687]\n",
      "epoch:[ 0/ 5], batch[ 810/ 938], loss:[G:1.771111,D:0.097556]\n",
      "epoch:[ 0/ 5], batch[ 820/ 938], loss:[G:1.326371,D:0.097953]\n",
      "epoch:[ 0/ 5], batch[ 830/ 938], loss:[G:2.032887,D:0.112056]\n",
      "epoch:[ 0/ 5], batch[ 840/ 938], loss:[G:1.311007,D:0.249403]\n",
      "epoch:[ 0/ 5], batch[ 850/ 938], loss:[G:1.680124,D:0.533729]\n",
      "epoch:[ 0/ 5], batch[ 860/ 938], loss:[G:1.161634,D:0.232195]\n",
      "epoch:[ 0/ 5], batch[ 870/ 938], loss:[G:1.637448,D:0.228317]\n",
      "epoch:[ 0/ 5], batch[ 880/ 938], loss:[G:0.903679,D:0.198246]\n",
      "epoch:[ 0/ 5], batch[ 890/ 938], loss:[G:1.802944,D:0.092292]\n",
      "epoch:[ 0/ 5], batch[ 900/ 938], loss:[G:1.493123,D:0.127900]\n",
      "epoch:[ 0/ 5], batch[ 910/ 938], loss:[G:0.960513,D:0.181052]\n",
      "epoch:[ 0/ 5], batch[ 920/ 938], loss:[G:1.278933,D:0.152958]\n",
      "epoch:[ 0/ 5], batch[ 930/ 938], loss:[G:1.140160,D:0.147540]\n",
      "epoch:[ 1/ 5], batch[   0/ 938], loss:[G:0.907168,D:0.213496]\n",
      "epoch:[ 1/ 5], batch[  10/ 938], loss:[G:0.843330,D:0.440514]\n",
      "epoch:[ 1/ 5], batch[  20/ 938], loss:[G:2.241678,D:0.177110]\n",
      "epoch:[ 1/ 5], batch[  30/ 938], loss:[G:1.506415,D:0.159303]\n",
      "epoch:[ 1/ 5], batch[  40/ 938], loss:[G:1.445541,D:0.123101]\n",
      "epoch:[ 1/ 5], batch[  50/ 938], loss:[G:2.960022,D:0.230751]\n",
      "epoch:[ 1/ 5], batch[  60/ 938], loss:[G:0.948571,D:0.174750]\n",
      "epoch:[ 1/ 5], batch[  70/ 938], loss:[G:2.294697,D:0.116204]\n",
      "epoch:[ 1/ 5], batch[  80/ 938], loss:[G:2.593367,D:0.217823]\n",
      "epoch:[ 1/ 5], batch[  90/ 938], loss:[G:1.094462,D:0.120518]\n",
      "epoch:[ 1/ 5], batch[ 100/ 938], loss:[G:3.416152,D:0.082114]\n",
      "epoch:[ 1/ 5], batch[ 110/ 938], loss:[G:1.242890,D:0.234192]\n",
      "epoch:[ 1/ 5], batch[ 120/ 938], loss:[G:1.241296,D:0.260308]\n",
      "epoch:[ 1/ 5], batch[ 130/ 938], loss:[G:1.559092,D:0.166823]\n",
      "epoch:[ 1/ 5], batch[ 140/ 938], loss:[G:1.381228,D:0.166665]\n",
      "epoch:[ 1/ 5], batch[ 150/ 938], loss:[G:2.233670,D:0.406478]\n",
      "epoch:[ 1/ 5], batch[ 160/ 938], loss:[G:1.574937,D:0.101667]\n",
      "epoch:[ 1/ 5], batch[ 170/ 938], loss:[G:1.295131,D:0.102881]\n",
      "epoch:[ 1/ 5], batch[ 180/ 938], loss:[G:0.911510,D:0.442108]\n",
      "epoch:[ 1/ 5], batch[ 190/ 938], loss:[G:0.837088,D:0.243067]\n",
      "epoch:[ 1/ 5], batch[ 200/ 938], loss:[G:1.537271,D:0.121502]\n",
      "epoch:[ 1/ 5], batch[ 210/ 938], loss:[G:2.075903,D:0.113036]\n",
      "epoch:[ 1/ 5], batch[ 220/ 938], loss:[G:1.406131,D:0.130002]\n",
      "epoch:[ 1/ 5], batch[ 230/ 938], loss:[G:3.315027,D:0.210474]\n",
      "epoch:[ 1/ 5], batch[ 240/ 938], loss:[G:1.163442,D:0.333734]\n",
      "epoch:[ 1/ 5], batch[ 250/ 938], loss:[G:1.718191,D:0.095077]\n",
      "epoch:[ 1/ 5], batch[ 260/ 938], loss:[G:1.622738,D:0.095524]\n",
      "epoch:[ 1/ 5], batch[ 270/ 938], loss:[G:1.807455,D:0.120614]\n",
      "epoch:[ 1/ 5], batch[ 280/ 938], loss:[G:2.335198,D:0.210993]\n",
      "epoch:[ 1/ 5], batch[ 290/ 938], loss:[G:0.822856,D:0.296403]\n",
      "epoch:[ 1/ 5], batch[ 300/ 938], loss:[G:1.787025,D:0.286682]\n",
      "epoch:[ 1/ 5], batch[ 310/ 938], loss:[G:2.211176,D:0.346407]\n",
      "epoch:[ 1/ 5], batch[ 320/ 938], loss:[G:1.692124,D:0.125489]\n",
      "epoch:[ 1/ 5], batch[ 330/ 938], loss:[G:1.772304,D:0.129373]\n",
      "epoch:[ 1/ 5], batch[ 340/ 938], loss:[G:1.556991,D:0.161194]\n",
      "epoch:[ 1/ 5], batch[ 350/ 938], loss:[G:1.765306,D:0.089910]\n",
      "epoch:[ 1/ 5], batch[ 360/ 938], loss:[G:1.889295,D:0.136531]\n",
      "epoch:[ 1/ 5], batch[ 370/ 938], loss:[G:1.260371,D:0.130391]\n",
      "epoch:[ 1/ 5], batch[ 380/ 938], loss:[G:2.901793,D:0.683684]\n",
      "epoch:[ 1/ 5], batch[ 390/ 938], loss:[G:1.708207,D:0.393469]\n",
      "epoch:[ 1/ 5], batch[ 400/ 938], loss:[G:2.108515,D:0.165662]\n",
      "epoch:[ 1/ 5], batch[ 410/ 938], loss:[G:1.167843,D:0.164235]\n",
      "epoch:[ 1/ 5], batch[ 420/ 938], loss:[G:1.609105,D:0.124763]\n",
      "epoch:[ 1/ 5], batch[ 430/ 938], loss:[G:1.507660,D:0.100153]\n",
      "epoch:[ 1/ 5], batch[ 440/ 938], loss:[G:0.991804,D:0.186242]\n",
      "epoch:[ 1/ 5], batch[ 450/ 938], loss:[G:1.570411,D:0.091797]\n",
      "epoch:[ 1/ 5], batch[ 460/ 938], loss:[G:4.676663,D:0.307264]\n",
      "epoch:[ 1/ 5], batch[ 470/ 938], loss:[G:1.518966,D:0.325793]\n",
      "epoch:[ 1/ 5], batch[ 480/ 938], loss:[G:0.830273,D:0.373072]\n",
      "epoch:[ 1/ 5], batch[ 490/ 938], loss:[G:1.750729,D:0.098193]\n",
      "epoch:[ 1/ 5], batch[ 500/ 938], loss:[G:2.157466,D:0.273561]\n",
      "epoch:[ 1/ 5], batch[ 510/ 938], loss:[G:1.317514,D:0.161184]\n",
      "epoch:[ 1/ 5], batch[ 520/ 938], loss:[G:1.409239,D:0.142491]\n",
      "epoch:[ 1/ 5], batch[ 530/ 938], loss:[G:2.230162,D:0.098756]\n",
      "epoch:[ 1/ 5], batch[ 540/ 938], loss:[G:1.733347,D:0.065138]\n",
      "epoch:[ 1/ 5], batch[ 550/ 938], loss:[G:1.843928,D:0.073575]\n",
      "epoch:[ 1/ 5], batch[ 560/ 938], loss:[G:2.219690,D:0.199034]\n",
      "epoch:[ 1/ 5], batch[ 570/ 938], loss:[G:1.289026,D:0.109903]\n",
      "epoch:[ 1/ 5], batch[ 580/ 938], loss:[G:1.738653,D:0.075511]\n",
      "epoch:[ 1/ 5], batch[ 590/ 938], loss:[G:2.168266,D:0.143740]\n",
      "epoch:[ 1/ 5], batch[ 600/ 938], loss:[G:1.978320,D:0.033937]\n",
      "epoch:[ 1/ 5], batch[ 610/ 938], loss:[G:1.318800,D:0.086240]\n",
      "epoch:[ 1/ 5], batch[ 620/ 938], loss:[G:2.490714,D:1.129464]\n",
      "epoch:[ 1/ 5], batch[ 630/ 938], loss:[G:0.979376,D:0.540396]\n",
      "epoch:[ 1/ 5], batch[ 640/ 938], loss:[G:2.159378,D:0.493612]\n",
      "epoch:[ 1/ 5], batch[ 650/ 938], loss:[G:1.337842,D:0.239107]\n",
      "epoch:[ 1/ 5], batch[ 660/ 938], loss:[G:1.413626,D:0.219107]\n",
      "epoch:[ 1/ 5], batch[ 670/ 938], loss:[G:1.167703,D:0.180924]\n",
      "epoch:[ 1/ 5], batch[ 680/ 938], loss:[G:1.698604,D:0.138138]\n",
      "epoch:[ 1/ 5], batch[ 690/ 938], loss:[G:1.509677,D:0.088999]\n",
      "epoch:[ 1/ 5], batch[ 700/ 938], loss:[G:2.196933,D:0.109826]\n",
      "epoch:[ 1/ 5], batch[ 710/ 938], loss:[G:1.061424,D:0.403930]\n",
      "epoch:[ 1/ 5], batch[ 720/ 938], loss:[G:1.213992,D:0.185157]\n",
      "epoch:[ 1/ 5], batch[ 730/ 938], loss:[G:1.680643,D:0.111255]\n",
      "epoch:[ 1/ 5], batch[ 740/ 938], loss:[G:1.544756,D:0.105365]\n",
      "epoch:[ 1/ 5], batch[ 750/ 938], loss:[G:1.681347,D:0.087322]\n",
      "epoch:[ 1/ 5], batch[ 760/ 938], loss:[G:0.969030,D:0.516917]\n",
      "epoch:[ 1/ 5], batch[ 770/ 938], loss:[G:3.317220,D:0.256746]\n",
      "epoch:[ 1/ 5], batch[ 780/ 938], loss:[G:1.493624,D:0.159735]\n",
      "epoch:[ 1/ 5], batch[ 790/ 938], loss:[G:1.263785,D:0.251247]\n",
      "epoch:[ 1/ 5], batch[ 800/ 938], loss:[G:1.805881,D:0.126126]\n",
      "epoch:[ 1/ 5], batch[ 810/ 938], loss:[G:1.549845,D:0.285776]\n",
      "epoch:[ 1/ 5], batch[ 820/ 938], loss:[G:3.776753,D:0.381457]\n",
      "epoch:[ 1/ 5], batch[ 830/ 938], loss:[G:2.373148,D:0.078801]\n",
      "epoch:[ 1/ 5], batch[ 840/ 938], loss:[G:1.949271,D:0.072240]\n",
      "epoch:[ 1/ 5], batch[ 850/ 938], loss:[G:2.386029,D:0.119597]\n",
      "epoch:[ 1/ 5], batch[ 860/ 938], loss:[G:1.252501,D:0.276134]\n",
      "epoch:[ 1/ 5], batch[ 870/ 938], loss:[G:1.944945,D:1.911200]\n",
      "epoch:[ 1/ 5], batch[ 880/ 938], loss:[G:2.028786,D:0.233894]\n",
      "epoch:[ 1/ 5], batch[ 890/ 938], loss:[G:1.663901,D:0.126626]\n",
      "epoch:[ 1/ 5], batch[ 900/ 938], loss:[G:1.712203,D:0.118388]\n",
      "epoch:[ 1/ 5], batch[ 910/ 938], loss:[G:1.305953,D:0.160064]\n",
      "epoch:[ 1/ 5], batch[ 920/ 938], loss:[G:2.199391,D:0.184664]\n",
      "epoch:[ 1/ 5], batch[ 930/ 938], loss:[G:1.824619,D:0.138446]\n",
      "epoch:[ 2/ 5], batch[   0/ 938], loss:[G:1.617341,D:0.074210]\n",
      "epoch:[ 2/ 5], batch[  10/ 938], loss:[G:1.835387,D:0.048212]\n",
      "epoch:[ 2/ 5], batch[  20/ 938], loss:[G:1.722449,D:0.080966]\n",
      "epoch:[ 2/ 5], batch[  30/ 938], loss:[G:1.998753,D:0.040451]\n",
      "epoch:[ 2/ 5], batch[  40/ 938], loss:[G:2.206922,D:0.068093]\n",
      "epoch:[ 2/ 5], batch[  50/ 938], loss:[G:1.409596,D:0.117877]\n",
      "epoch:[ 2/ 5], batch[  60/ 938], loss:[G:1.473456,D:0.097789]\n",
      "epoch:[ 2/ 5], batch[  70/ 938], loss:[G:2.189369,D:0.040325]\n",
      "epoch:[ 2/ 5], batch[  80/ 938], loss:[G:2.149863,D:0.050146]\n",
      "epoch:[ 2/ 5], batch[  90/ 938], loss:[G:2.152481,D:0.031982]\n",
      "epoch:[ 2/ 5], batch[ 100/ 938], loss:[G:2.002629,D:0.034452]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-ba9c39e311f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m           \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"epoch:[{epoch:>2d}/{NUM_EPOCH:>2d}], batch[{batch_idx:>4d}/{len(dataloader):>4d}], loss:[G:{loss_gen:>6f},D:{disc_loss:6f}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m           \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__format__\u001b[0;34m(self, format_spec)\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__format__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__format__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__format__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(NUM_EPOCH):\n",
    "    loop = tqdm(dataLoader, leave=True)\n",
    "    for batch_idx, (x, _) in enumerate(dataloader):\n",
    "        x = x.to(DEVICE)\n",
    "\n",
    "        gen.train()\n",
    "        disc.train()\n",
    "        noise = torch.randn(BATCH_SIZE, noise_channel, 1, 1).to(DEVICE)\n",
    "        fake_gen = gen(noise)\n",
    "\n",
    "        fake_disc = disc(fake_gen).view(-1)\n",
    "        real_disc = disc(x).view(-1)\n",
    "\n",
    "        # train discrimnator\n",
    "        # make fake_gen 0, real_gen 1\n",
    "        fake_disc_loss = loss(fake_disc, torch.zeros_like(fake_disc))\n",
    "        real_disc_loss = loss(real_disc, torch.ones_like(real_disc))    \n",
    "        disc_loss = (fake_disc_loss + real_disc_loss) / 2\n",
    "        disc.zero_grad()\n",
    "        disc_loss.backward()\n",
    "        opt_disc.step()\n",
    "\n",
    "\n",
    "        # train generator\n",
    "        # make fake_gen 1\n",
    "        fake_gen = gen(noise)\n",
    "        fake_disc = disc(fake_gen).view(-1)\n",
    "        loss_gen = loss(fake_disc, torch.ones(fake_disc))\n",
    "        gen.zero_grad()\n",
    "        loss_gen.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "\n",
    "\n",
    "    if batch_idx % 10 == 0:\n",
    "\n",
    "        print(f\"epoch:[{epoch:>2d}/{NUM_EPOCH:>2d}], batch[{batch_idx:>4d}/{len(dataloader):>4d}], loss:[G:{loss_gen:>6f},D:{disc_loss:6f}]\")\n",
    "        gen.eval()\n",
    "        disc.eval()\n",
    "        # GAN sample real and gen_result\n",
    "        with torch.no_grad():\n",
    "          fake_out = gen(fix_noise)\n",
    "          grid_fake = torchvision.utils.make_grid(fake_out, normalize=True)\n",
    "          grid_real = torchvision.utils.make_grid(x, normalize=True)\n",
    "          real_writer.add_image(tag=\"real\", img_tensor=grid_real, global_step=epoch)\n",
    "          fake_writer.add_image(\"fake\", grid_fake, epoch)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMAbFA9PDOVSNLG19dH77G5",
   "name": "DCGAN.ipynb",
   "provenance": [
    {
     "file_id": "18GYypu0fEXzZDOWRfRMAdbSAhL60gJtr",
     "timestamp": 1643252009540
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
